{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l9RG7ORuMlw",
        "colab_type": "code",
        "outputId": "bf8436b5-c4e4-4fa8-f16a-747a21f9037b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D,Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import keras_metrics\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "#STOPWORDS = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objs as go\n",
        "import chart_studio.plotly as py\n",
        "import cufflinks\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "import plotly.figure_factory as ff\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "from plotly.offline import iplot\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEHmO7IZusKY",
        "colab_type": "code",
        "outputId": "32ff712e-2eb3-46b9-e268-644d209b016e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install keras_metrics"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhudGk0kuzki",
        "colab_type": "code",
        "outputId": "df245d10-fdf8-4b37-d5c0-5a0b914cabcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "olidData=pd.read_csv('training_data.tsv', sep='\\t')\n",
        "olidData\n",
        "olidData.text=olidData.text.astype(str)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>actual_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1157097496465825792</td>\n",
              "      <td>artists use clip studio paint please dm looks ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1159951246964547584</td>\n",
              "      <td>personORGillORGworkORGORGmightORGneedORGpens</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1161854610727997440</td>\n",
              "      <td>person 1 mycareer trailer huh</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1187418039719026689</td>\n",
              "      <td>aint settling piece shit ass hoes</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1157363369898328064</td>\n",
              "      <td>person person yea 100 part group</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134683</th>\n",
              "      <td>1160273231154176005</td>\n",
              "      <td>im done fucking gangbangs dumbass men love lik...</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134684</th>\n",
              "      <td>1162081126774652929</td>\n",
              "      <td>get rid trump asap person</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134685</th>\n",
              "      <td>1165255509202653185</td>\n",
              "      <td>exposing somebody love big l</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134686</th>\n",
              "      <td>1160347194370809861</td>\n",
              "      <td>parents really inconsiderate fuck</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134687</th>\n",
              "      <td>1188221501515980802</td>\n",
              "      <td>person still us league</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134688 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  ... actual_label\n",
              "0       1157097496465825792  ...          NOT\n",
              "1       1159951246964547584  ...          NOT\n",
              "2       1161854610727997440  ...          NOT\n",
              "3       1187418039719026689  ...     OFF, UNT\n",
              "4       1157363369898328064  ...          NOT\n",
              "...                     ...  ...          ...\n",
              "134683  1160273231154176005  ...     OFF, UNT\n",
              "134684  1162081126774652929  ...          NOT\n",
              "134685  1165255509202653185  ...          NOT\n",
              "134686  1160347194370809861  ...     OFF, UNT\n",
              "134687  1188221501515980802  ...          NOT\n",
              "\n",
              "[134688 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjjjdIT7vLZW",
        "colab_type": "code",
        "outputId": "50576f2e-7d82-41bb-d0ec-fc93391d3e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "maxWords = 50000\n",
        "maxLength = 250\n",
        "embedDimension = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=maxWords, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(olidData['text'])\n",
        "indexedWords = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(indexedWords))\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(olidData['text'].values)\n",
        "X_train = pad_sequences(X_train, maxlen=maxLength)\n",
        "print('Shape of data tensor:', X_train.shape)\n",
        "\n",
        "Y_train = pd.get_dummies(olidData['actual_label'])\n",
        "print('Shape of label tensor:', Y_train.shape)\n",
        "\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 77145 unique tokens.\n",
            "Shape of data tensor: (134688, 250)\n",
            "Shape of label tensor: (134688, 5)\n",
            "(134688, 250) (134688, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIKnustAvVJQ",
        "colab_type": "code",
        "outputId": "62cf12ef-e1f3-43b2-d343-4d1e20e05bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "biDirModel = Sequential()\n",
        "biDirModel.add(Embedding(maxWords, embedDimension, input_length=X_train.shape[1]))\n",
        "biDirModel.add(SpatialDropout1D(0.2))\n",
        "biDirModel.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
        "biDirModel.add(Dense(5, activation='softmax'))\n",
        "biDirModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(),keras_metrics.recall(),keras_metrics.f1_score()])\n",
        "print(biDirModel.summary())\n",
        "\n",
        "# BiLSTM model training\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "history = biDirModel.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 250, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1005      \n",
            "=================================================================\n",
            "Total params: 5,161,805\n",
            "Trainable params: 5,161,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 121219 samples, validate on 13469 samples\n",
            "Epoch 1/5\n",
            " 26624/121219 [=====>........................] - ETA: 25:41 - loss: 0.5635 - acc: 0.7948 - precision: 0.8794 - recall: 0.9455 - f1_score: 0.9112"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p06KAUdvDnSl",
        "colab_type": "text"
      },
      "source": [
        "Reading Test Data and then tokenizing test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD44BcrOvga_",
        "colab_type": "code",
        "outputId": "0c207216-0006-4986-9dcb-40f5217fc61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "source": [
        "testData=pd.read_csv('testData.csv')\n",
        "testData.tweet=testData.tweet.astype(str)\n",
        "testData\n",
        "\n",
        "tokenizer = Tokenizer(num_words=maxWords, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(testData['tweet'])\n",
        "indexedWords = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(indexedWords))\n",
        "\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(testData['tweet'].values)\n",
        "X_test = pad_sequences(X_test, maxlen=maxLength)\n",
        "print('Shape of data tensor:', X_test.shape)\n",
        "\n",
        "Y_test = pd.get_dummies(testData['actual_label'])\n",
        "print('Shape of label tensor:', Y_test.shape)\n",
        "\n",
        "accr = biDirModel.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n  Precision: {:0.3f}\\n  Recall: {:0.3f}\\n  F1Score: {:0.3f}'.format(accr[0],accr[1],accr[2],accr[3],accr[4]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>actual_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>86426</td>\n",
              "      <td>person ask native americans take</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>90194</td>\n",
              "      <td>person person go home youre drunk person #maga...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>16820</td>\n",
              "      <td>amazon investigating chinese employees selling...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>62688</td>\n",
              "      <td>person someone shouldvetaken piece shit volcano</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>43605</td>\n",
              "      <td>person person obama wanted liberals amp illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13235</th>\n",
              "      <td>13235</td>\n",
              "      <td>95338</td>\n",
              "      <td>person sometimes get strong vibes people mans ...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13236</th>\n",
              "      <td>13236</td>\n",
              "      <td>67210</td>\n",
              "      <td>benidorm creamfields maga shabby summer</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13237</th>\n",
              "      <td>13237</td>\n",
              "      <td>82921</td>\n",
              "      <td>person report garbage dont give crap</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>OTH</td>\n",
              "      <td>OFF, TIN, OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13238</th>\n",
              "      <td>13238</td>\n",
              "      <td>27429</td>\n",
              "      <td>person pussy</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OFF, UNT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13239</th>\n",
              "      <td>13239</td>\n",
              "      <td>46552</td>\n",
              "      <td>#spanishrevenge vs #justice #humanrights #free...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13240 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0     id  ... subtask_c   actual_label\n",
              "0               0  86426  ...       NaN       OFF, UNT\n",
              "1               1  90194  ...       IND  OFF, TIN, IND\n",
              "2               2  16820  ...       NaN            NOT\n",
              "3               3  62688  ...       NaN       OFF, UNT\n",
              "4               4  43605  ...       NaN            NOT\n",
              "...           ...    ...  ...       ...            ...\n",
              "13235       13235  95338  ...       IND  OFF, TIN, IND\n",
              "13236       13236  67210  ...       NaN            NOT\n",
              "13237       13237  82921  ...       OTH  OFF, TIN, OTH\n",
              "13238       13238  27429  ...       NaN       OFF, UNT\n",
              "13239       13239  46552  ...       NaN            NOT\n",
              "\n",
              "[13240 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "Found 20373 unique tokens.\n",
            "Shape of data tensor: (13240, 250)\n",
            "Shape of label tensor: (13240, 5)\n",
            "13240/13240 [==============================] - 48s 4ms/step\n",
            "Test set\n",
            "  Loss: 5.216\n",
            "  Accuracy: 0.365\n",
            "  Precision: 0.670\n",
            "  Recall: 0.445\n",
            "  F1Score: 0.535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VrArgDGYQXE",
        "colab_type": "code",
        "outputId": "5de20ee3-fc31-4af8-8054-9e393c454e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def InsertPredictions(test_data,model):\n",
        "    lstNot=[]\n",
        "    lstOffGrp=[]\n",
        "    lstOffInd=[]\n",
        "    lstOffOth=[]\n",
        "    lstOffUnt=[]\n",
        "    lst=[\"NOT\",\"OFF, TIN, GRP\",\"OFF, TIN, IND\",\"OFF, TIN, OTH\",\"OFF, UNT\"]\n",
        "    dd=testdata\n",
        "    lst_text = dd['tweet'].tolist()\n",
        "    y_prob = model.predict(test_data)\n",
        "    for prob in y_prob:\n",
        "      lstNot.append(prob[0])\n",
        "      lstOffGrp.append(prob[1])\n",
        "      lstOffInd.append(prob[2])\n",
        "      lstOffOth.append(prob[3])\n",
        "      lstOffUnt.append(prob[4])\n",
        "    y_classes = y_prob.argmax(axis=-1)\n",
        "    lst_classes=y_classes.tolist()\n",
        "    lst_predictions = [lst[i] for i in lst_classes]\n",
        "    lst_original=dd['actual_label'].tolist()\n",
        "    lst_prob=y_prob.tolist()\n",
        "    df = pd.DataFrame(lst_text,columns =['tweet'])\n",
        "    df['Original']=lst_original\n",
        "    df['Predictions']=lst_predictions\n",
        "    df['Not Off.']=lstNot\n",
        "    df['Off. Group']=lstOffGrp\n",
        "    df['Off. Ind.']=lstOffInd\n",
        "    df['Off. Others']=lstOffOth\n",
        "    df['Off. Untargeted']=lstOffUnt\n",
        "    lstSummary=[]\n",
        "    for index, row in df.iterrows():\n",
        "      if row['Original']==row['Predictions']:\n",
        "        lstSummary.append(1)\n",
        "      else:\n",
        "        lstSummary.append(0)\n",
        "    df['IsCorrect']=lstSummary\n",
        "    return df\n",
        "\n",
        "predicted=InsertPredictions(X_test,biDirModel)\n",
        "predicted\n",
        "\n",
        "#y_classes = keras.np_utils.probas_to_classes(y_proba)\n",
        "#y_classes[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Original</th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Not Off.</th>\n",
              "      <th>Off. Group</th>\n",
              "      <th>Off. Ind.</th>\n",
              "      <th>Off. Others</th>\n",
              "      <th>Off. Untargeted</th>\n",
              "      <th>IsCorrect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>person ask native americans take</td>\n",
              "      <td>OFF, UNT</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999746</td>\n",
              "      <td>1.639387e-04</td>\n",
              "      <td>1.290461e-05</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>5.612267e-07</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>person person go home youre drunk person #maga...</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>4.525802e-07</td>\n",
              "      <td>4.465868e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>1.615599e-07</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon investigating chinese employees selling...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>1.603185e-06</td>\n",
              "      <td>2.925236e-06</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.141915e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>person someone shouldvetaken piece shit volcano</td>\n",
              "      <td>OFF, UNT</td>\n",
              "      <td>OFF, UNT</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.697569e-04</td>\n",
              "      <td>5.206646e-02</td>\n",
              "      <td>0.000620</td>\n",
              "      <td>9.470415e-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>person person obama wanted liberals amp illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999974</td>\n",
              "      <td>1.549825e-05</td>\n",
              "      <td>4.031895e-06</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>3.677636e-07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13235</th>\n",
              "      <td>person sometimes get strong vibes people mans ...</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>2.503552e-06</td>\n",
              "      <td>1.425680e-06</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>6.626452e-08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13236</th>\n",
              "      <td>benidorm creamfields maga shabby summer</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999979</td>\n",
              "      <td>2.891651e-06</td>\n",
              "      <td>3.625252e-06</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>5.847009e-06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13237</th>\n",
              "      <td>person report garbage dont give crap</td>\n",
              "      <td>OFF, TIN, OTH</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>1.629019e-03</td>\n",
              "      <td>9.966840e-01</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>1.108795e-03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13238</th>\n",
              "      <td>person pussy</td>\n",
              "      <td>OFF, UNT</td>\n",
              "      <td>OFF, TIN, IND</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>1.542336e-02</td>\n",
              "      <td>8.800029e-01</td>\n",
              "      <td>0.017194</td>\n",
              "      <td>8.730197e-02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13239</th>\n",
              "      <td>#spanishrevenge vs #justice #humanrights #free...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0.999966</td>\n",
              "      <td>8.350864e-06</td>\n",
              "      <td>2.670301e-06</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>9.360813e-06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13240 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  ... IsCorrect\n",
              "0                       person ask native americans take  ...         0\n",
              "1      person person go home youre drunk person #maga...  ...         0\n",
              "2      amazon investigating chinese employees selling...  ...         1\n",
              "3        person someone shouldvetaken piece shit volcano  ...         1\n",
              "4      person person obama wanted liberals amp illega...  ...         1\n",
              "...                                                  ...  ...       ...\n",
              "13235  person sometimes get strong vibes people mans ...  ...         0\n",
              "13236            benidorm creamfields maga shabby summer  ...         1\n",
              "13237               person report garbage dont give crap  ...         0\n",
              "13238                                       person pussy  ...         0\n",
              "13239  #spanishrevenge vs #justice #humanrights #free...  ...         1\n",
              "\n",
              "[13240 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU4nHGZHfHx3",
        "colab_type": "code",
        "outputId": "8b22e572-7c81-42b1-815e-da7e5d7def03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def calScores(frame):\n",
        "  lst=['NOT','OFF, TIN, GRP','OFF, TIN, IND','OFF, TIN, OTH','OFF, UNT']\n",
        "  lstFscore=[]\n",
        "  for item in lst:\n",
        "    tp=len(frame[(frame['IsCorrect']==1) & (frame['Predictions']==item)])\n",
        "    fp=len(frame[(frame['IsCorrect']==0) & (frame['Predictions']==item)])\n",
        "    #precision=tp/tp+fp\n",
        "    precision=tp/(tp+fp)\n",
        "    print(\"Precision for \"+item+\" : \"+str(precision))\n",
        "    fn=len(frame[(frame['Original']==item) & (frame['Predictions']!=item)])\n",
        "    recall=tp/(tp+fn)\n",
        "    print(\"Recall for \"+item+\" : \"+str(recall))\n",
        "    fScore=(2*precision*recall)/(precision+recall)\n",
        "    lstFscore.append(fScore)\n",
        "  return lstFscore\n",
        "\n",
        "tp=len(predicted[(predicted['IsCorrect']==1) & (predicted['Predictions']=='OFF, UNT')])\n",
        "fp=len(predicted[(predicted['IsCorrect']==0) & (predicted['Predictions']=='OFF, UNT')])\n",
        "print(tp,fp)\n",
        "calScores(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196 327\n",
            "Precision for NOT : 0.7524561403508772\n",
            "Recall for NOT : 0.9703619909502262\n",
            "Precision for OFF, TIN, GRP : 0.46265060240963857\n",
            "Recall for OFF, TIN, GRP : 0.1787709497206704\n",
            "Precision for OFF, TIN, IND : 0.7319711538461539\n",
            "Recall for OFF, TIN, IND : 0.25301204819277107\n",
            "Precision for OFF, TIN, OTH : 0.17142857142857143\n",
            "Recall for OFF, TIN, OTH : 0.030379746835443037\n",
            "Precision for OFF, UNT : 0.37476099426386233\n",
            "Recall for OFF, UNT : 0.37404580152671757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8476284584980237,\n",
              " 0.2578912021490934,\n",
              " 0.37604198826798396,\n",
              " 0.05161290322580645,\n",
              " 0.3744030563514804]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYcPl6dFfvJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}